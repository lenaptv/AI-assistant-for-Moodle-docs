# AI-assistant-for-Moodle-docs

Этот проект реализует RAG (Retrieval-Augmented Generation) систему поиска по документации Moodle. В Colab запускается RAG-pipeline, который извлекает релевантные документы из векторного хранилища Chroma, а затем генерирует ответ с помощью локальной SLM (Qwen2.5-0.5B-Instruct). REST API запускается через FastAPI, а публичный доступ организован с помощью ngrok.
Данный ИИ-помощник понимает русский и английский язык (все используемые модели в пайплайн мультиязычные). Также ИИ-помощник "помнит" диалог.

 ### Что в проекте
RAG-пайплайн:  
- с помощью 'Choma_DB_Create.ipynb': формируется векторная БД chroma_db  из документации Moodle (код парсинга в файле Parsing_Moodle.ipynb) с использованием легковесной эмбеддинговой мультиязычной модели Qwen3-Embedding-0.6B -одной из лучших доступных согласно https://huggingface.co/spaces/mteb/leaderboard
- гибридный поиск: полнотекстовый + семантический поиск (веса: 0.5, 0.5)
- используется ранжировщик (чтобы избежать Lost-in-the-middle эффекта), также легковесной и мультиязычный BAAI/bge-reranker-v2-m3 - из лучших доступных согласно https://huggingface.co/spaces/mteb/leaderboard
- для генерации используется open-source SLM "Qwen2.5-0.5B-Instruct"+ системный промпт
- в цепочке RAG-pipeline используется память предыдущего разговора

FastAPI сервер с эндпоинтом /ask для вопросов

ngrok для публикации локального сервера в Интернет

Использование GPU (T4) в Colab для ускорения инференса

### Подготовка данных
- С помощью Parsing_Moodle.ipynb выполните парсинг актуальной документации Moodle
- Затем с помощью Choma_DB_Create.ipynb сформируйте векторное/индексное хранилище в БД Chroma. Для формирования эмбеддингов используется Qwen3-Embedding-0.6B
- 
  ### Как запустить в Google Colab ноутбук RAG_Moodle_Qwen2.5_FastAPI.ipynb

1. Подключение GPU и необходимые установки   
В Colab:
- Среда выполнения → Изменить тип среды выполнения → выбрать GPU (например, T4) → Сохранить.
- Подключите Google disk, предварительно сохраните на него базу данных (всю папку chroma_db_qwen3)
- Запустите ячейки с установкой необходимых пакетов
- Модели загружаются из Hugging Face, поэтому проверьте наличие интернет-соединения

2. Инициализация RAG-пайплайна
- В ячйке с RAG-пайплайн проверьте путь к векторной базе chroma_db_qwen3
- Затем запустите код в данной ячейке

3. FastAPI - приложение
- Предварительно зарегистрируйтесь на https://ngrok.com/ и в ячейке с FastAPI-приложением введите токен в строку: conf.get_default().auth_token = "ваш_токен_ngrok"
- После запуска данной ячейки в выводе будет публичный URL вида https://xxxxxxxx.ngrok-free.app
- Откройте ссылку http://xxxxxxxx.ngrok-free.app/docs
- Откроется Swagger-интерфейс FastAPI:

нажмите на /ask.

нажмите "Try it out".

введите Ваш вопрос в JSON, например: {"query": "Как добавить пользователя в Moodle?"}.

нажмите "Execute" 

немного подождите и увидете результат

4. Завершение работы
- После заврешения работы просто прервите выполнение ячейки с FastAPI - приложением, это остановит FastAPI и ngrok
- Остановите использование GPU
